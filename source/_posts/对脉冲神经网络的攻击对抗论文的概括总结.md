---
title: 对脉冲神经网络的攻击对抗论文的概括总结
date: 2020-02-21 14:37:29
tags: [攻击对抗,脉冲神经网络]
categories: [攻击对抗]
mathjax: true
---

- 主要问题：攻击样本，即向原始样本中添加一些人眼无法察觉的噪声，这样的噪声不会影响人类的识别，但是却很容易愚弄DNN，使其作出与正确答案完全不同的判定。
  - 目前snn在对抗攻击方面的研究还比较少
- 常用方法有基于梯度的/基于内容的
  - 在snn中又可以分为基于原始数据的/基于脉冲的

1. 《A Comprehensive Analysis on Adversarial Robustness of Spiking Neural Networks》arXiv:1905.02704v1 

   - 提出了一种简单的机制，可以根据SNN模型参数生成对抗性输入，而无需在脉冲域中进行任何额外non-trivial 的梯度计算。

   - 算法：

     1. 构建具有相同网络拓扑结构的神经网络模型ANN′，并初始化。

     2. 讲之前训练得到的$M_{SNN}$模型的权值覆盖ANN′。

     3. 干净数据集的Poisson脉冲序列生成频率编码的输入$X_{rate}$。

     4. 用$X_{rate}$输入ANN′模型生成FGSM攻击样本。

   - 总结：实际上作者提出的方法还是通过ann得到的攻击样本，没有解决snn难以获取时空梯度的问题。

2. 《Exploring Adversarial Attack in Spiking Neural Networks with Spike-Compatible Gradient》arXiv:2001.01587v1 [cs.NE]1 Jan 2020

   - 问题：
     1. snn时空梯度难以获取
     2. 梯度不相容
     3. 梯度消失
   - 解决方法
     1. backpropagation through time (BPTT)-inspired learning algorithms 应用于SNN
     2. 梯度脉冲（G2S）转换器
        - 概率采样

          - 首先将梯度归一化为[0，1]。 

          - 然后，对归一化的梯度图进行采样，以生成具有相同形状的二进制掩码，

        - 符号提取——生成一个三元梯度图

          - 三元梯度图：每个元素都位于{−1，0，1}中，在累加到二进制值为{0，1}的脉冲输入后，可以保持脉冲格式。 

        - 溢出感知转换

          - 虽然上述$\delta s_{k}^{\prime \prime}$可以是三元的，但它不能保证由输入梯度累积产生的攻击样本仍然局限于{0，1}。
          - 流感知梯度变换来限制最终对抗例子的范围
     3. 梯度触发器（GT）
        - 元素选择

          - 梯度初始化，将所有元素设置为γ，它控制GT后非零梯度的数量。
          - 之前的概率抽样仍然适用于生成掩码$\delta_{mask}$。

        - 梯度构造

          - 为了保持攻击样本的脉冲格式，我们只需翻转选定区域中脉冲输入的状态。
   - 总结：目前目标是实现stdp上的黑盒攻击，最基本的stdp是无监督学习算法，理论上是没有反向传播的，也就是说不能使用基于梯度计算。那本篇文章的大方向其实没有太大参考价值。但是我认为梯度脉冲转换器和梯度触发器的设计细节上，比如概率采样/符号提取/溢出感知转换也许在stdp处理原始数据转换为脉冲的过程中可以参考。

3. 《Adversarial Training for Probabilistic Spiking Neural Networks》arXiv:1802.08567v2 [stat.ML] 26 Feb 2018

   - 首次研究了在白盒对抗攻击下通过ML（Maximum Likelihood）训练的SNN的敏感性，并提出了一种可靠的训练机制，该机制被证明可以增强白盒攻击下SNN的性能。

   - 算法：

     - **扰动类型**：消除攻击；增加攻击；翻转(Flip)攻击

     - **扰动类型的选择**

       1. 找到在给定模型θ下可能性最小的类别c^LL:

       2. 选择干扰类型，使得攻击强度最大，也就是判定为目标类别$c^{LL}$的可能性最大。

   - 总结：该算法是在脉冲上加入扰动，且不是基于梯度的，如果要应用于stdp应该只需把扰动类型选择过程中计算分类概率的函数改成对应的概率就可以。虽然文章写的是白盒攻击，但是文章的最后表示可以迁移到黑盒攻击。

4. 《SNN under Attack: are Spiking Deep Belief Networks vulnerable to Adversarial Examples? 》arXiv:1902.01147v1 [cs.LG]4 Feb 2019

   - 开发了一种黑盒攻击方法，可通过贪婪算法自动生成无法感知且强大的攻击样本，这是SNN的首创。

   - 概念：

      	1. 不可感知性：确保人类不会注意到的干扰
          - 如果像素具有**较高的标准偏差**，则意味着**添加到该像素的干扰不容易被人眼察觉**。
         	2. 健壮性：先前的算法只考虑目标类别概率最大，而未考虑目标类别与其他类别的概率差，即应该增加目标类别的概率与其他类别的最高概率之间的差。（间隙函数）

   - 算法

     - 目标：迭代使间隙函数最大化，从而使攻击更加鲁棒；同时将样本之间的距离保持在所需阈值以下，以保持不被察觉。

     - 步骤：

       1. 为选定的N·N个像素计算了标准偏差
       2. 计算间隙函数Gap，即目标类别的概率与最大概率的其他类别之间的差。
       3. 算法决定是对像素施加正噪声还是负噪声

       4. 根据这些值与间隙函数之间的差异，并同时考虑标准偏差，我们计算出变化优先级。
       5. 将变化优先级VariationPriority排序，并为优先级最高的M个像素加入干扰。

       该算法通过将原始输入图像替换为创建的对抗图像来开始下一次迭代。当原始示例与对抗示例之间的距离超过最大感知距离时，迭代将终止。

   - 总结：4中否定和3中提出的健壮性的衡量方法，提出了新的健壮性的衡量方式，即间隙函数。3中是修改脉冲，而4是修改原是图像的。

- 总结：1、2都是利用基于梯度的，但是目前目标是实现stdp上的黑盒攻击，最基本的stdp是无监督学习算法，理论上是没有反向传播的，也就是说不能基于梯度计算。接下来的研究我认为应该关注一些基于内容的或者其他非基于梯度的算法。

- | **Article**                      | 是否基于梯度 | 白盒 | 黑盒 | 修改像素or脉冲 |
  | -------------------------------- | ------------ | ---- | ---- | -------------- |
  | [1] Saima Sharmin et al,2019     | Y            | Y    | Y    | Pixel          |
  | [2] Ling Liang et al,2020        | Y            | Y    | N    | both           |
  | [3] Alireza Bagheri et al,2018   | N            | Y    | N    | Spiking        |
  | [4] Alberto Marchisio et al,2019 | N            | N    | Y    | Pixel          |